{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping\n",
    "\n",
    "\n",
    "### Extracting text files from webscraper.io CSV results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "with open('sample-wireless-news.csv', encoding='utf-8') as f:  # change the file name for your file\n",
    "    df = pd.read_csv(f) # read csv into a pandas dataframe\n",
    "df.head(5) # display the first five rows of the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export script\n",
    "\n",
    "Use the script below to export your scraped content to a directory of text files *if your text column contains plain text*. \n",
    "\n",
    "Please note the following:\n",
    "\n",
    "- this will only work with data in the CSV format exported from webscraper.io\n",
    "- you should inspect the webscraper output in CSV format first, to save repeating this process if changes are needed\n",
    "- you must load the CSV into this notebook as a pandas dataframe using the cell above FIRST\n",
    "- you must create a directory called 'textfiles' in the same directory as this notebook (or wherever you run the code from)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# once your data is loaded in the cell above and you've created a 'textfiles' directory, run this cell    \n",
    "\n",
    "text_column_name = 'story_text' #modify this if your column is named something else\n",
    "\n",
    "for idx, col in df.iterrows():   \n",
    "    if isinstance(col['title'],str) and isinstance(col['date'],str) and isinstance(col[text_column_name],str):\n",
    "        filename = 'textfiles/{}.txt'.format(col['title'][:35] + '-' + col['date'])\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "        # the format(col['title'] bit above determines the output filename - part of the title and the date\n",
    "            f.write(col[text_column_name])\n",
    "            print('Writing file ' + str(idx), filename)\n",
    "    else:\n",
    "        print('No string data - ignoring row',idx)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note about grouped type selector\n",
    "\n",
    "It is possible that text columns from the webscraper.io can contain JSON (e.g. if you capture multiple paragraphs using the 'Grouped' selector). In that case, use this exporter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# once your data is loaded in the cell above and you've created a 'textfiles' directory, run this cell    \n",
    "import json\n",
    "\n",
    "text_column_name = 'story_text' #modify this if your column is named something else\n",
    "\n",
    "for idx, col in df.iterrows():   \n",
    "    if isinstance(col['title'],str) and isinstance(col['date'],str) and isinstance(col[text_column_name],str):\n",
    "        filename = 'textfiles/{}.txt'.format(col['title'][:35] + '-' + col['date'])\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "        # the format(col['title'] bit above determines the output filename - part of the title and the date\n",
    "            chunks = json.loads(col[text_column_name]) # this parses the json structure\n",
    "            for chunk in chunks:\n",
    "                f.write(chunk[text_column_name] + ' ')\n",
    "            print('Writing file ' + str(idx), filename)\n",
    "    else:\n",
    "        print('No string data - ignoring row',idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note if you trying to join multiple elements from a page\n",
    "\n",
    "It is possible that you may have scraped text using webscraper.io in such a way that there are multiple rows in the CSV for the same URL. This exporter should help consolidate them into one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(['web-scraper-order'], ascending = [True]) # reorder the dataframe by web-scraper-order so you get text in order\n",
    "\n",
    "text_column_name = 'story_text' #modify this if your column is named something else\n",
    "\n",
    "for idx, col in df.iterrows():   \n",
    "    if isinstance(col['title'],str) and isinstance(col['date'],str) and isinstance(col[text_column_name],str):\n",
    "        filename = 'textfiles/{}.txt'.format(col['title'][:35] + '-' + col['date'])\n",
    "        with open(filename, 'a', encoding='utf-8') as f: #appending rather than overwriting\n",
    "            f.write(col[text_column_name])\n",
    "            print('Writing file ' + str(idx), filename)\n",
    "    else:\n",
    "        print('No string data - ignoring row',idx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
